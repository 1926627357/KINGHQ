// Author: Haiquan Wang
2020/1/18 17:18
vgg+cifar跑的速度(cpu)非常慢，后面实验的时候一定要考虑使用gpu

2020/1/18 17:47
在跑vgg+cifar的时候使用了错误的（之前lenet+mnist）loss function，计算出来的loss为负数，导致模型不收敛

2020/1/18 20:07
CPU上跑的多个进程会瓜分CPU的算力，server的算力也会影响到通信，我觉得每个服务器上不要跑太多的进程，另外一个worker挂在一个gpu上比较好
可以考虑限制cpu使用率，不过似乎该机器没有安装相应的工具

2020/1/19 12:00
我修复了前端index.html中server在check staleness中无法读取输入框中数值的bug

2020/1/19 14:06
我修改了log工具，将“每step步长取一个数据点”的操作放在write方法中执行，即在写文件之前执行

2020/1/19 20:12
今日meeting总结：
1. 在其中的一个worker上面采集实验数据的做法对吗
2. shuffle关闭之后能够保证每次吐出来的数据是一样的吗
3. 在只有一个worker的情况下去测试BSP与ASP的性能
4. learning rate在有无average的BSP中的影响是要考虑的
5. 考虑到两个进程能够挂在一个gpu的这种情况
6. 试一下task-set能不能限制一个linux进程的使用cpu核数

solution：
所有进程按照一定的概率sleep一小段时间，我觉得straggler的情形可以分成两种情况：
    1. 就是有一个进程慢（比如现在有1080又有2080，那么它们的运算能力就是差的比较多）
    2. 虽然大家都一样，但是在云端大家的网络和运算力是波动的，那么用随机blocked的方式来模拟我认为很合适

2020/1/20 16:20
在做Single_16_4系列的实验时每一轮都采点导致图像出错，我觉得应该是每一次apply才去采一次点（主要是因为要
模拟BSP的情况）

2020/1/20 16:47
实验时发现BSP_na的表现与Single_16_4表现不一致，存在bug，原因就在于我server端的clear accumulate的逻辑
有问题，我写的变成了每一轮都要clear accumulate了。

2020/1/21 12:05
我将今晚讨论到的问题罗列如下：
	1. single-server的设计是否能够保证：a.performance可接受b.不会损害到synchronization
	2. 同质环境下，SSP，BSP，ASP三者可能在收敛上区别不大，可以考虑给每个worker都加入随机的扰动来进行实验
	3. 找一些合适的neural network model进行实验，这一部分可以咨询这边做算法的人

2020/2/5 12:13
fix了单节点运行梯度不更新的bug，原因就是strategy没有load正确的Single.json文件

2020/2/8 11:07
meeting:
	1. 能否保证convergence的正确性
	2. 如何去测实验的数据
	3. 如何去slow worker，人工制造出heter的环境

2020/2/20 16:05
conda create --name pytorch python=3.6
需要的依赖库（持续补充）：
conda install pandas json5 tqdm matplotlib

anaconda 
conda create --name pytorch python=3.6
conda remove -n pytorch --all

pytorch install:
conda install numpy ninja pyyaml mkl mkl-include setuptools cmake cffi
conda install -c pytorch magma-cuda100
git clone --recursive https://github.com/pytorch/pytorch
cd pytorch
# if you are updating an existing checkout
# git submodule sync
# git submodule update --init --recursive
conda install -c conda-forge openmpi
python setup.py clean
#export CUDA_HOME=/home/haiqwa/Documents/cuda/
#export CUDNN_LIB_DIR=/home/haiqwa/Documents/cudnn/cuda/lib64
#export CUDNN_INCLUDE_DIR=/home/haiqwa/Documents/cudnn/cuda/include
#export CUDNN_LIBRARY=libcudnn.so
#export CPLUS_INCLUDE_PATH=/home/haiqwa/Documents/cuda/include:$CPLUS_INCLUDE_PATH C_INCLUDE_PATH=/home/haiqwa/Documents/cuda/include:$C_INCLUDE_PATH
#export LIBRARY_PATH=/home/haiqwa/Documents/cuda/lib64:$LIBRARY_PATH
export USE_NINJA=OFF
export CMAKE_PREFIX_PATH=${CONDA_PREFIX:-"$(dirname $(which conda))/../"}
python setup.py install



torchvision install
git clone https://github.com/pytorch/vision.git
conda install pillow
python setup.py install
"if" failed to install, you could add this line to the ~/.bashrc:
export PYTHONPATH="/home/haiqwa/Download/vision/build/lib.linux-x86_64-3.6/:$PYTHONPATH"